{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan_validation_dongkeun_github.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGnFgmUBNtEU"
      },
      "source": [
        "# **실험 개요**  \r\n",
        "심전도 신호에 대한 정상/비정상 판별을 위해 Generative model의 재생성 특성을 활용하였다.  \r\n",
        "generative model은 GAN을 사용하였다.  \r\n",
        "1) 데이터 로드 및 전처리 작업 수행  \r\n",
        "2)GAN 구현 및 학습  \r\n",
        "3)GAN 성능 평가  \r\n",
        "4)머신러닝 분류기 사용  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzNQ2_GlYamE"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras import initializers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy9xQAhwYfTw"
      },
      "source": [
        "# 사용할 라이브러리 선언\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "#for data preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#for modeling\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.model_selection import train_test_split #training and testing data split\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#filter warnings\n",
        "import warnings\n",
        "\n",
        "# 우리의 랜덤 노이즈 벡터의 차원을 설정합니다.\n",
        "random_dim = 121"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvEDbI79YlsR"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/total_data/심전도 신호 데이터.csv\",header=None) # one class anomaly detection 임으로 정상에 대해서만 먼저 학습 진행"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K7FXl_EYnEw"
      },
      "source": [
        "RANDOM_SEED=42\n",
        "X_train,X_test=train_test_split(data,test_size=0.1,random_state=RANDOM_SEED) #train_test_split을 이용하여 전체 데이터에서 train용과 test용을 분리\n",
        "X_train = X_train.astype(float) / 255\n",
        "#print(X_train) # 데이터에 마지막 열을 읽어오는데 NaN이 존재한다\n",
        "X_train=X_train.dropna(axis=1) # 데이터에서 NaN이 존재한다면 해당 열을 제거\n",
        "X_test = X_test.astype(float) / 255\n",
        "X_test=X_test.dropna(axis=1) # 데이터에서 NaN이 존재한다면 해당 열을 제거\n",
        "input_dim = X_train.shape[1] # input 차원을 위하여 입력한 csv파일의 첫번째 shape값 사용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNCaoxqcYv2n"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "# 사용할 라이브러리 선언\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "\n",
        "#for data preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#for modeling\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.model_selection import train_test_split #training and testing data split\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#filter warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "RANDOM_SEED = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swlft3wvYwhA"
      },
      "source": [
        "def get_generator():\n",
        "    model = Sequential()\n",
        "    model.add(layers.Dense(256, input_dim=random_dim, \n",
        "                           kernel_initializer=initializers.RandomNormal(stddev=0.02))) #random_dim에 본인이 학습을 원하는 차원을 입력해준다.\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "    \n",
        "    model.add(layers.Dense(512))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "    model.add(layers.Dense(1024))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "    \n",
        "    model.add(layers.Dense(121, activation='tanh'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='Nadam')\n",
        "   \n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUwW0FNWYx85"
      },
      "source": [
        "def get_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(layers.Dense(1024,  input_dim=121, \n",
        "                           kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Dense(512))\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.3))\n",
        "   \n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='Nadam')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZlUTM9oY0XI"
      },
      "source": [
        "def get_gan_network(discriminator, random_dim, generator):\n",
        "    # 우리는 Generator와 Discriminator를 동시에 학습시키고 싶을 때 trainable을 False로 설정합니다.\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    # GAN 입력 (노이즈)은 위에서 설정했습니다.\n",
        "    gan_input = Input(shape=(random_dim,))\n",
        "\n",
        "    # Generator의 결과는 가짜 데이터(흉내)입니다.\n",
        "    x = generator(gan_input)\n",
        "\n",
        "    # Discriminator의 결과는 입력 데이터가 진짜인지 가짜인지에 대한 확률입니다.\n",
        "    gan_output = discriminator(x)\n",
        "\n",
        "    gan = Model(inputs=gan_input, outputs=gan_output)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer='Nadam')\n",
        "    return gan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTzCpHegY088"
      },
      "source": [
        "epochs=150\n",
        "batch_size=128\n",
        "# train 데이터를 128 사이즈의 batch 로 나눕니다.\n",
        "batch_count = X_train.shape[0] // batch_size\n",
        "\n",
        "# 우리의 GAN 네트워크를 만듭니다.\n",
        "generator = get_generator()\n",
        "discriminator = get_discriminator()\n",
        "gan = get_gan_network(discriminator, random_dim, generator)\n",
        "\n",
        "for e in range(1, epochs+1):\n",
        "    # print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "    for _ in tqdm(range(batch_count)):\n",
        "        # 입력으로 사용할 random 노이즈\n",
        "        noise = np.random.normal(0, 1, size=[batch_size, random_dim]) #이걸 사용하는 이유는 0~1사이의 값을 가지는 난수를 발생시키는(생성자에 구분시키는 능력주려고)\n",
        "        #print(noise.shape) #(128, 121)이 나온다 #121은 제가 정한 입력 차원\n",
        "        image_batch = X_train.to_numpy()[np.random.randint(0, X_train.to_numpy().shape[0], size=batch_size)]\n",
        "\n",
        "        # 가짜 데이터를 생성합니다.\n",
        "        generated_images = generator.predict(noise)\n",
        "        X = np.concatenate([image_batch, generated_images]) #concatenate --> np 합쳐준다\n",
        "        # print(generated_images.shape) # ECG줬을 때 (98112, 121)이 나온 것 처럼 (128 ,121)이 나온다. batch size를 128로 입력에 주었으니까!\n",
        "        # print(image_batch.shape)\n",
        "        # print(X.shape)\n",
        "        y_dis = np.zeros(2*batch_size)\n",
        "        y_dis[:batch_size] = 0.9\n",
        "        #print(y_dis.shape) # (256,)\n",
        "        # Discriminator를 학습시킵니다.\n",
        "        discriminator.trainable = True\n",
        "        discriminator.train_on_batch(X, y_dis) # 생성자는 실제 데이터인 X와 가짜인 y_dis를 분별하도록 훈련 #train_on_batch를 쓰면 validation이 안된다.\n",
        "        #우선적으로 생성자를 만들때는 시간의 효율을 위해 train_on_batch를 사용 그러나 개발환경에따라 fit으로 한다면 효율이 더 좋을지도\n",
        "\n",
        "        # Generator를 학습시킵니다.\n",
        "        noise = np.random.normal(0, 1, size=[batch_size, random_dim]) #generator는 가짜를 생성하도록 학습\n",
        "        y_gen = np.ones(batch_size)\n",
        "        gan.fit(noise, y_gen,shuffle=True,validation_split=0.3,verbose=0) #validation을 위하여 fit사용 validation은 입력데이터에서 7:3의 비율\n",
        "\n",
        "    # if e == 1 or e % 20 == 0:\n",
        "    #     plot_generated_images(e, generator)\n",
        "#아래는 모델 생성\n",
        "model_json = generator.to_json() \n",
        "with open(\"/content/drive/My Drive/model/model_real_gan_vali_epoch200.json\", \"w\") as json_file: \n",
        "  json_file.write(model_json)\n",
        "generator.save_weights(\"/content/drive/My Drive/model/model_real_gan_vali_epoch200.h5\") \n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6MKrREUGH-f"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ1Ht0KMldj0",
        "outputId": "fcc6e180-eaac-414e-b760-01feaf11594d"
      },
      "source": [
        "from tensorflow.compat.v2.keras.models import model_from_json\n",
        "\n",
        "\n",
        "json_file = open(\"/content/drive/MyDrive/model/model_real_gan_vali_epoch150_2.json\", \"r\") \n",
        "loaded_model_json = json_file.read() \n",
        "json_file.close()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "loaded_model.load_weights(\"/content/drive/MyDrive/model/model_real_gan_vali_epoch150_2.h5\") \n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyT3ydKoltwz"
      },
      "source": [
        "generated_images2 = loaded_model.predict(X_test) # GAN에서 생성자를 사용하여 입력에 대한 재생성 데이터 생성"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F3vAuImGIs3"
      },
      "source": [
        "rms = sqrt(mean_squared_error(X_test, generated_images2,squared=False)) #성능 평가"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm1HPdKLGXij",
        "outputId": "0507ed68-8be7-4633-f360-2ae952d4032c"
      },
      "source": [
        "print(rms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3056275797847904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlK7RbeiZDc7"
      },
      "source": [
        "# plt.subplot(2,1,1)\n",
        "# plt.plot(generated_images2[10,:])\n",
        "# plt.subplot(2,1,2)\n",
        "# plt.plot(X_test.to_numpy()[10,:])\n",
        "plt.plot(X_test.to_numpy()[30,:])\n",
        "plt.plot(generated_images2[30,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1iZ7bnPZEnk"
      },
      "source": [
        "import sklearn\n",
        "x_sk=sklearn.metrics.pairwise.cosine_similarity(X_test.to_numpy(), generated_images2, dense_output=True)\n",
        "print(data.shape)\n",
        "print(x_sk.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt8u9q9w73As"
      },
      "source": [
        "# outlier 제거!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y0cG0U472Th"
      },
      "source": [
        "#정상 신호에 대한 outlier 제거 수행\n",
        "df2 = pd.DataFrame()\n",
        "data_real=data.dropna(axis=1)\n",
        "predictions_all = loaded_model.predict(data_real)\n",
        "j=0\n",
        "for i in range(0,92673):\n",
        "  x_sk=sklearn.metrics.pairwise.cosine_similarity(data_real.to_numpy()[i,:].reshape(1,121), predictions_all[i,:].reshape(1,121), dense_output=True) #각 신호에 따른 유사도 평가\n",
        "  #x_sk=abs(x_sk)\n",
        "  if x_sk.mean()>0.4: #outlier 제거\n",
        "    df2[j]=data_real.to_numpy()[i,:]\n",
        "    j=j+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUq1kCaK8eUv"
      },
      "source": [
        "print(df2.shape)\n",
        "df2=df2.transpose()\n",
        "print(df2.shape)\n",
        "plt.plot(df2.to_numpy()[1,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY2IB-uJytTu"
      },
      "source": [
        "X_train_df2,X_test_df2=train_test_split(df2,test_size=0.1,random_state=RANDOM_SEED) #train_test_split을 이용하여 전체 데이터에서 train용과 test용을 분리\n",
        "X_train_df2 = X_train_df2.astype(float) / 255\n",
        "X_train_df2=X_train_df2.dropna(axis=1) # 데이터에서 NaN이 존재한다면 해당 열을 제거\n",
        "X_test_df2 = X_test_df2.astype(float) / 255\n",
        "X_test_df2=X_test_df2.dropna(axis=1) # 데이터에서 NaN이 존재한다면 해당 열을 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDy7L94UlXmW"
      },
      "source": [
        "print(X_test_df2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm5ZH5Iwx1Qs"
      },
      "source": [
        "df22 = pd.DataFrame()\n",
        "data2=pd.read_csv(\"/content/drive/My Drive/total_data/비정상 심전도 데이터.csv\")\n",
        "data2=data2.dropna(axis=1)\n",
        "data_paf=data2\n",
        "predictions_all_paf = loaded_model.predict(data_paf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-3HBNXqyCij"
      },
      "source": [
        "print(predictions_all_paf.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN1V6jcCyFag"
      },
      "source": [
        "G = np.isnan(predictions_all_paf)\n",
        "for i in range(0,122640):\n",
        "  if G[i].any()== True:\n",
        "    print(i,\"이상한 값\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgES5Oz4yIze"
      },
      "source": [
        "#비정상 심방세동에 대한 outlier제거 수행\n",
        "j2=0\n",
        "for i in range(0,122640):\n",
        "  # if i != 90020: \n",
        "  x_sk=sklearn.metrics.pairwise.cosine_similarity(data_paf.to_numpy()[i,:].reshape(1,121), predictions_all_paf[i,:].reshape(1,121), dense_output=True) #각 신호에 따른 유사도 평가\n",
        "  #x_sk=abs(x_sk)\n",
        "  #print(x_sk)\n",
        "  if x_sk.mean()<0.7: #outlier 제거\n",
        "    df22[j2]=data_paf.to_numpy()[i,:]\n",
        "    j2=j2+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPKEkDT-ySyK"
      },
      "source": [
        "print(df22.shape)\n",
        "df22=df22.transpose()\n",
        "print(df22.shape)\n",
        "plt.plot(df22.to_numpy()[1,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVLR27oCyTxK",
        "outputId": "0dbe0931-783e-499c-cf0f-87fcf5a0e795"
      },
      "source": [
        "X_train_df22,X_test_df22=train_test_split(df22,test_size=0.1,random_state=RANDOM_SEED) #train_test_split을 이용하여 전체 데이터에서 train용과 test용을 분리\n",
        "X_train_df22 = X_train_df22.astype(float) / 255\n",
        "X_train_df22=X_train_df22.dropna(axis=1) # 데이터에서 NaN이 존재한다면 해당 열을 제거\n",
        "X_test_df22 = X_test_df22.astype(float) / 255\n",
        "X_test_df22=X_test_df22.dropna(axis=1) # 데이터에서 NaN이 존재한다면 해당 열을 제거\n",
        "print(X_train_df22.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(106402, 121)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30euJAW48mRm"
      },
      "source": [
        "#이상치 제거 후 모델 재학습\n",
        "X_train_df2,X_test_df2=train_test_split(df2,test_size=0.1,random_state=RANDOM_SEED) #train_test_split을 이용하여 전체 데이터에서 train용과 test용을 분리\n",
        "X_train_df2 = X_train_df2.astype(float) / 255\n",
        "X_train_df2=X_train_df2.dropna(axis=1) # 데이터에서 NaN이 존재한다면 해당 열을 제거\n",
        "X_test_df2 = X_test_df2.astype(float) / 255\n",
        "X_test_df2=X_test_df2.dropna(axis=1) # 데이터에서 NaN이 존재한다면 해당 열을 제거\n",
        "print(X_train_df2.shape)\n",
        "random_dim = X_train_df2.shape[1] # input 차원을 위하여 입력한 csv파일의 첫번째 shape값 사용\n",
        "\n",
        "epochs=150\n",
        "batch_size=128\n",
        "# train 데이터를 128 사이즈의 batch 로 나눕니다.\n",
        "batch_count = X_train.shape[0] // batch_size\n",
        "\n",
        "# 우리의 GAN 네트워크를 만듭니다.\n",
        "generator = get_generator()\n",
        "discriminator = get_discriminator()\n",
        "gan = get_gan_network(discriminator, random_dim, generator)\n",
        "\n",
        "for e in range(1, epochs+1):\n",
        "    # print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "    for _ in tqdm(range(batch_count)):\n",
        "        # 입력으로 사용할 random 노이즈\n",
        "        noise = np.random.normal(0, 1, size=[batch_size, random_dim]) #이걸 사용하는 이유는 0~1사이의 값을 가지는 난수를 발생시키는(생성자에 구분시키는 능력주려고)\n",
        "        #print(noise.shape) #(128, 121)이 나온다 #121은 제가 정한 입력 차원\n",
        "        image_batch = X_train.to_numpy()[np.random.randint(0, X_train_df2.to_numpy().shape[0], size=batch_size)]\n",
        "\n",
        "        # 가짜 데이터를 생성합니다.\n",
        "        generated_images = generator.predict(noise)\n",
        "        X = np.concatenate([image_batch, generated_images]) #concatenate --> np 합쳐준다\n",
        "        # print(generated_images.shape) # 우리가 ecg줬을 때 (98112, 121)이 나온 것 처럼 (128 ,121)이 나온다. batch size를 128로 입력에 주었으니까!\n",
        "        # print(image_batch.shape)\n",
        "        # print(X.shape)\n",
        "        y_dis = np.zeros(2*batch_size)\n",
        "        y_dis[:batch_size] = 0.9\n",
        "        #print(y_dis.shape) # (256,)\n",
        "        # Discriminator를 학습시킵니다.\n",
        "        discriminator.trainable = True\n",
        "        discriminator.train_on_batch(X, y_dis) # 생성자는 실제 데이터인 X와 가짜인 y_dis를 분별하도록 훈련 #train_on_batch를 쓰면 validation이 안된다.\n",
        "        #우선적으로 생성자를 만들때는 시간의 효율을 위해 train_on_batch를 사용 그러나 개발환경에따라 fit으로 한다면 효율이 더 좋을지도\n",
        "\n",
        "        # Generator를 학습시킵니다.\n",
        "        noise = np.random.normal(0, 1, size=[batch_size, random_dim]) #generator는 가짜를 생성하도록 학습\n",
        "        y_gen = np.ones(batch_size)\n",
        "        gan.fit(noise, y_gen,shuffle=True,validation_split=0.3,verbose=0) #validation을 위하여 fit사용 validation은 입력데이터에서 7:3의 비율\n",
        "\n",
        "    # if e == 1 or e % 20 == 0:\n",
        "    #     plot_generated_images(e, generator)\n",
        "model_json = generator.to_json() \n",
        "with open(\"/content/drive/My Drive/model/model_real_gan_vali_epoch150_outlier.json\", \"w\") as json_file: \n",
        "  json_file.write(model_json)\n",
        "generator.save_weights(\"/content/drive/My Drive/model/model_real_gan_vali_epoch150_outlier.h5\") \n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpoSKg8k89Xv"
      },
      "source": [
        "from tensorflow.compat.v2.keras.models import model_from_json\n",
        "\n",
        "\n",
        "json_file = open(\"/content/drive/MyDrive/model/model_real_gan_vali_epoch150_outlier.json\", \"r\") \n",
        "loaded_model_json = json_file.read() \n",
        "json_file.close()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "loaded_model.load_weights(\"/content/drive/MyDrive/model/model_real_gan_vali_epoch150_outlier.h5\") \n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10xTCH1M9ktC"
      },
      "source": [
        "predictions_df2 = loaded_model.predict(X_test_df2)\n",
        "# mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
        "# error_df = pd.DataFrame({'reconstruction_error': mse,\n",
        "#                         'true_class': y_test})\n",
        "# error_df.describe()\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(X_test.to_numpy()[3,:])\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(predictions_df2[3,:])\n",
        "import sklearn\n",
        "#x_sk_df2=sklearn.metrics.pairwise.cosine_similarity(X_test_df2.to_numpy()[0,:].reshape(1,121), predictions_df2[0,:].reshape(1,121), dense_output=True)\n",
        "x_sk_df2=sklearn.metrics.pairwise.cosine_similarity(X_test_df2.to_numpy(), predictions_df2, dense_output=True)\n",
        "# print(x_sk.size)\n",
        "print(x_sk_df2.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0edyGKezAx8"
      },
      "source": [
        "## 일반 데이터와 GAN의 재생성 데이터를 토대로 머신 러닝 분류기가 비정상/정상 수행하도록 실험"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uvR7wr_zABn"
      },
      "source": [
        "X_train_nonLinear_features = loaded_model.predict(X_train)\n",
        "X_test_nonLinear_features = loaded_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcbLcmmwzKYj",
        "outputId": "af53e3eb-abd7-4a64-b35c-3355189cc653"
      },
      "source": [
        "print(X_train_nonLinear_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(83405, 121)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDX5creKRCIY"
      },
      "source": [
        "X_train1=np.concatenate((X_train, X_train_nonLinear_features[0:10000]), axis=0)\n",
        "X_test1=np.concatenate((X_test_df2, X_test_nonLinear_features), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etRBWaRbRHaA"
      },
      "source": [
        "print(X_train1.shape) #그냥하면 에러가 발생하니 reshape로 (*,1) 모양으로 만들어주쟈"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mJvRf_FzMug"
      },
      "source": [
        "y_pred_classes_ori_df2 = np.ones(shape=(93405,)) #정답이니까 1로 채운다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2gAhcBAzPpo"
      },
      "source": [
        "y_pred_classes_ori_df2 = y_pred_classes_ori_df2.astype(np.int8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB9Bcu_SgPCk"
      },
      "source": [
        "y_pred_classes_ori_df2=y_pred_classes_ori_df2.reshape(93405,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSoYVFsQYryZ",
        "outputId": "564f1f7f-6c50-4aec-d81d-9db5b6f453c2"
      },
      "source": [
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9268, 121)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDf4dQU3a5od"
      },
      "source": [
        "y_pred_classes_ori_df2_test = np.ones(shape=(9268,)) #정답이니까 1로 채운다\r\n",
        "y_pred_classes_ori_df2_test = y_pred_classes_ori_df2_test.astype(np.int8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsB49e6ShQVS"
      },
      "source": [
        "y_pred_classes_ori_df2_test=y_pred_classes_ori_df2_test.reshape(9268,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV0YOf4PzRXn"
      },
      "source": [
        "from sklearn import svm\n",
        "clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
        "clf.fit(X_train_df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZifMx8-zXTM"
      },
      "source": [
        "pre=clf.predict(X_test_df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfTfx8mq1jyU"
      },
      "source": [
        "print(pre)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgDtCfJ4901_"
      },
      "source": [
        "from sklearn.model_selection import KFold # K-Fold Cross Validation \n",
        "from sklearn.model_selection import cross_val_score # 점수 평가\n",
        "from sklearn.model_selection import cross_val_predict # 예측\n",
        "from sklearn import metrics # accuracy measure\n",
        "from sklearn.metrics import confusion_matrix # confusion matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feSodbZ_93A1"
      },
      "source": [
        "# y_pred_classes_ori_df2 = np.ones(shape=(4389,)) #정답이니까 1로 채운다\n",
        "# sns.heatmap(confusion_matrix(y_pred_classes_ori_df2,y_pred_classes_df2), annot=True, fmt = '1.0f') #정상 heatmap 그리기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRjRFzfqzm-T"
      },
      "source": [
        "print(X_test_nonLinear_features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZcTJQvPzkok"
      },
      "source": [
        "y_pred_classes_ori_df2_samll= np.ones(shape=(4389,)) #정답이니까 1로 채운다\n",
        "# y_pred_classes_ori_df2_samll= np.ones(shape=(9268,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecsL4iQfzfPv"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "ac1=accuracy_score(pre,y_pred_classes_ori_df2_samll)\n",
        "print(ac1)\n",
        "#0.896252211677658"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN4ogUAKzwF9"
      },
      "source": [
        "sns.heatmap(confusion_matrix(y_pred_classes_ori_df2_samll,pre), annot=True, fmt = '1.0f') #정상 heatmap 그리기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKIBgiF11PKZ"
      },
      "source": [
        "from sklearn import svm\n",
        "clf2 = svm.OneClassSVM(nu=0.08, kernel=\"rbf\", gamma=15,shrinking=False) #gamma=20 nu=0.1 f1 scoer 80.8점, gamma=20 nu=0.08 f1 score 81.1\n",
        "clf2.fit(X_train_df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDuMELXj1kP1"
      },
      "source": [
        "pre_10=clf2.predict(X_test_df2)\n",
        "y_pred_classes_ori_df2_samll_10= np.ones(shape=(4389,)) #정답이니까 1로 채운다\n",
        "print(pre_10)\n",
        "ac1_10=accuracy_score(pre_10,y_pred_classes_ori_df2_samll_10)\n",
        "print(ac1_10)\n",
        "#0.9046163744571337"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIeSXYGN-ZSP"
      },
      "source": [
        "sns.heatmap(confusion_matrix(y_pred_classes_ori_df2_samll_10,pre_10), annot=True, fmt = '1.0f') #정상 heatmap 그리기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UjCF5c0-1-d"
      },
      "source": [
        "#isolationforest 사용\n",
        "from sklearn.ensemble import IsolationForest\n",
        "if_clf = IsolationForest(contamination=0.08, max_features=1.0, max_samples=1.0, n_estimators=40)  # Obtained using grid search"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI2KyM_7jfJF"
      },
      "source": [
        "#Feature Scaling\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train1)\r\n",
        "\r\n",
        "X_train1_plus = scaler.transform(X_train1)\r\n",
        "X_test_df2_plus = scaler.transform(X_test_df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh29Yh1lVQnR",
        "outputId": "4c6211b4-b0a6-478e-e45b-734f02c95237"
      },
      "source": [
        "# Take PCA to reduce feature space dimensionality\r\n",
        "pca2 = PCA(n_components=121, whiten=True)\r\n",
        "pca2 = pca2.fit(X_train1_plus)\r\n",
        "print('Explained variance percentage = %0.2f' % sum(pca2.explained_variance_ratio_))\r\n",
        "X_train1_plus = pca2.transform(X_train1_plus)\r\n",
        "X_test_df2_plus = pca2.transform(X_test_df2_plus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained variance percentage = 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kayb4wnqN5Ze",
        "outputId": "80da46f1-fcde-4a46-a908-8fe008fcac7a"
      },
      "source": [
        "if_clf.fit(X_train1_plus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IsolationForest(behaviour='deprecated', bootstrap=False, contamination=0.08,\n",
              "                max_features=1.0, max_samples=1.0, n_estimators=40, n_jobs=None,\n",
              "                random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fisInO-K_Ohs",
        "outputId": "8133a7fb-f941-404c-8ca4-57381e545883"
      },
      "source": [
        "pre_10_2_bagging=if_clf.predict(X_test_df2_plus)\n",
        "y_pred_classes_ori_df2_samll_10_2_bagging= np.ones(shape=(4389,)) #정답이니까 1로 채운다\n",
        "ac1_10_2_bagging=accuracy_score(pre_10_2_bagging,y_pred_classes_ori_df2_samll_10_2_bagging)\n",
        "print(ac1_10_2_bagging)\n",
        "#0.881936625382017"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8956482114376851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faGCpQqa_q08"
      },
      "source": [
        "### original data + 재생서 데이터를 이용한 svm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et3DoL_bEgse"
      },
      "source": [
        "from sklearn import svm\n",
        "clf3 = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=18) #gamma=20 nu=0.1 f1 scoer 84.7점\n",
        "clf3.fit(X_train1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lwU6y22Evb4"
      },
      "source": [
        "pre_10_2_ori=clf3.predict(X_test_df2)\n",
        "#y_pred_classes_ori_df2_samll_10_2= np.ones(shape=(4389,)) #정답이니까 1로 채운다\n",
        "y_pred_classes_ori_df2_samll_10_2_ori= np.ones(shape=(4389,)) #정답이니까 1로 채운다\n",
        "ac1_10_2_ori=accuracy_score(pre_10_2_ori,y_pred_classes_ori_df2_samll_10_2_ori)\n",
        "print(ac1_10_2_ori)\n",
        "#0.8582917806015763 #0.7934695190606402"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYi1Mt-wE6sn"
      },
      "source": [
        "sns.heatmap(confusion_matrix(y_pred_classes_ori_df2_samll_10_2_ori,pre_10_2_ori), annot=True, fmt = '1.0f') #정상 heatmap 그리기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KmtMI-YCJYE"
      },
      "source": [
        "## 특성 스케일링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCJ5oU-jCLfC"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "minMaxScaler = MinMaxScaler()\r\n",
        "minMaxScaler.fit(X_train1) \r\n",
        "train_data_minMaxScaled = minMaxScaler.transform(X_train1)\r\n",
        "test_data_minMaxScaled = minMaxScaler.transform(X_test_df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzKeEIluFAii"
      },
      "source": [
        "from sklearn import svm\r\n",
        "clf4 = svm.OneClassSVM(nu=0.08, kernel=\"rbf\", gamma=0.001) #nu=0.08, kernel=\"rbf\", gamma=0.001\r\n",
        "clf4.fit(train_data_minMaxScaled) #아웃라이어 제거 후 다시 모델 로드 x 기존 모델 사용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EPED_nmvRRo"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoloqtnIFQJP"
      },
      "source": [
        "pre_10_2=clf4.predict(test_data_minMaxScaled)\r\n",
        "#y_pred_classes_ori_df2_samll_10_2= np.ones(shape=(4389,)) #정답이니까 1로 채운다\r\n",
        "y_pred_classes_ori_df2_samll_10_2= np.ones(shape=(4389,)) #정답이니까 1로 채운다\r\n",
        "ac1_10_2_mimax=accuracy_score(pre_10_2,y_pred_classes_ori_df2_samll_10_2)\r\n",
        "print(ac1_10_2_mimax)\r\n",
        "#0.8582917806015763 #0.7934695190606402"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8fCruh5vtj1"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pW5D10jFRxh"
      },
      "source": [
        "sns.heatmap(confusion_matrix(y_pred_classes_ori_df2_samll_10_2,pre_10_2), annot=True, fmt = '1.0f') #정상 heatmap 그리기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6A0mtQQFbCT"
      },
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler\r\n",
        "maxAbsScaler = MaxAbsScaler()\r\n",
        "maxAbsScaler.fit(X_train1)\r\n",
        "train_data_maxAbsScaled = maxAbsScaler.transform(X_train1)\r\n",
        "test_data_maxAbsScaled = maxAbsScaler.transform(X_test_df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFxwRK9PFllN"
      },
      "source": [
        "from sklearn import svm\r\n",
        "clf5 = svm.OneClassSVM(nu=0.08, kernel=\"rbf\", gamma=0.001) #스케일링 하면 감마를 낮추자\r\n",
        "clf5.fit(train_data_maxAbsScaled) #아웃라이어 제거 후 다시 모델 로드 x 기존 모델 사용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow6kVPqvFpZ9"
      },
      "source": [
        "pre_10_2_2=clf5.predict(test_data_maxAbsScaled)\r\n",
        "#y_pred_classes_ori_df2_samll_10_2= np.ones(shape=(4389,)) #정답이니까 1로 채운다\r\n",
        "y_pred_classes_ori_df2_samll_10_2_2= np.ones(shape=(4389,)) #정답이니까 1로 채운다\r\n",
        "ac1_10_2=accuracy_score(pre_10_2_2,y_pred_classes_ori_df2_samll_10_2_2)\r\n",
        "print(ac1_10_2)\r\n",
        "#0.8582917806015763 #0.8447804407270387"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gF5uCMnFzv_"
      },
      "source": [
        "sns.heatmap(confusion_matrix(y_pred_classes_ori_df2_samll_10_2_2,pre_10_2_2), annot=True, fmt = '1.0f') #정상 heatmap 그리기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTIs7_WmGJ_V"
      },
      "source": [
        "## feature에 대하여 진행해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7R5jta8IdLn"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from sklearn.ensemble import IsolationForest\r\n",
        "from sklearn import svm\r\n",
        "\r\n",
        "# Apply standard scaler to output from resnet50\r\n",
        "ss = StandardScaler()\r\n",
        "ss.fit(X_train1)\r\n",
        "X_train_nonLinear_features = ss.transform(X_train1)\r\n",
        "X_test_nonLinear_features = ss.transform(X_test_nonLinear_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiZFeN_QIn76"
      },
      "source": [
        "# Take PCA to reduce feature space dimensionality\r\n",
        "pca = PCA(n_components=121, whiten=True)\r\n",
        "pca = pca.fit(X_train_nonLinear_features)\r\n",
        "print('Explained variance percentage = %0.2f' % sum(pca.explained_variance_ratio_))\r\n",
        "X_train_nonLinear_features = pca.transform(X_train_nonLinear_features)\r\n",
        "X_test_nonLinear_features = pca.transform(X_test_nonLinear_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIyRLj_OItqS"
      },
      "source": [
        "# Train classifier and obtain predictions for OC-SVM\r\n",
        "oc_svm_clf = svm.OneClassSVM(gamma=0.08, kernel='rbf', nu=0.08)  # Obtained using grid search\r\n",
        "oc_svm_clf.fit(X_train_nonLinear_features) #아웃라이어 제거 후 다시 모델 로드 x 기존 모델 사용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3PABKVwI1LR"
      },
      "source": [
        "pre_10_2_3=oc_svm_clf.predict(X_test_nonLinear_features)\r\n",
        "#y_pred_classes_ori_df2_samll_10_2= np.ones(shape=(4389,)) #정답이니까 1로 채운다\r\n",
        "y_pred_classes_ori_df2_samll_10_2_3= np.ones(shape=(9268,)) #정답이니까 1로 채운다\r\n",
        "ac1_10_2_3=accuracy_score(pre_10_2_3,y_pred_classes_ori_df2_samll_10_2_3)\r\n",
        "print(ac1_10_2_3)\r\n",
        "#0.8582917806015763 #0.7934695190606402 #0.8974709501025291"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwAElOmP47Fn"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from sklearn.ensemble import IsolationForest\r\n",
        "from sklearn import svm\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "X_train_nonLinear_features = loaded_model.predict(X_train)\r\n",
        "X_test_nonLinear_features = loaded_model.predict(X_test)\r\n",
        "# Apply standard scaler to output from resnet50\r\n",
        "ss = StandardScaler()\r\n",
        "ss.fit(X_train_nonLinear_features)\r\n",
        "X_train_nonLinear_features_fin = ss.transform(X_train_nonLinear_features)\r\n",
        "X_test_nonLinear_features_fin = ss.transform(X_test_nonLinear_features)\r\n",
        "# # Take PCA to reduce feature space dimensionality\r\n",
        "# pca = PCA(n_components=121, whiten=True)\r\n",
        "# pca = pca.fit(X_train_nonLinear_features_fin)\r\n",
        "# print('Explained variance percentage = %0.2f' % sum(pca.explained_variance_ratio_))\r\n",
        "# X_train_nonLinear_features_fin = pca.transform(X_train_nonLinear_features_fin)\r\n",
        "# X_test_nonLinear_features_fin = pca.transform(X_test_nonLinear_features_fin)\r\n",
        "# Train classifier and obtain predictions for OC-SVM\r\n",
        "oc_svm_clf = svm.OneClassSVM(gamma=0.1, kernel='rbf', nu=0.08)  # Obtained using grid search\r\n",
        "oc_svm_clf.fit(X_train_nonLinear_features) #아웃라이어 제거 후 다시 모델 로드 x 기존 모델 사용\r\n",
        "pre_10_2_3=oc_svm_clf.predict(X_test_nonLinear_features)\r\n",
        "#y_pred_classes_ori_df2_samll_10_2= np.ones(shape=(4389,)) #정답이니까 1로 채운다\r\n",
        "y_pred_classes_ori_df2_samll_10_2_3= np.ones(shape=(9268,)) #정답이니까 1로 채운다\r\n",
        "ac1_10_2_3=accuracy_score(pre_10_2_3,y_pred_classes_ori_df2_samll_10_2_3)\r\n",
        "print(ac1_10_2_3)\r\n",
        "#0.8582917806015763 #0.7934695190606402 #0.8974709501025291"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc9d59QEzxBh"
      },
      "source": [
        "## paf svm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni_jHs4zv5Z9"
      },
      "source": [
        "# 데이터 로드 및 전처리 작업 수행\n",
        "data2=pd.read_csv(\"/content/drive/My Drive/total_data/비정상 심전도 데이터.csv\")\n",
        "data2=data2.dropna(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t0JJzPlv-ec"
      },
      "source": [
        "X_train2,X_test2=train_test_split(data2,test_size=0.1,random_state=RANDOM_SEED) #train_test_split을 이용하여 전체 데이터에서 train용과 test용을 분리\n",
        "X_train2 = X_train2.astype(float) / 255\n",
        "#print(X_train2) # 데이터에 마지막 열을 읽어오는데 NaN이 존재한다\n",
        "X_train2=X_train2.dropna(axis=1) # 데이터에서 NaN이 존재한다면 해당 열을 제거\n",
        "#print(X_train2)\n",
        "tmp=X_train2.to_numpy()\n",
        "#print(\"도식화 할 데이터\")\n",
        "#print(tmp[0,:])\n",
        "#plt.plot(tmp[5,:]) # ecg 데이터 하나만 그래프로 도식화 해보자\n",
        "X_test2 = X_test2.astype(float) / 255\n",
        "X_test2=X_test2.dropna(axis=1) # 데이터에서 NaN이 존재한다면 해당 열을 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDf4DqUGfnNv"
      },
      "source": [
        "fake_paf=loaded_model.predict(X_train2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI_Na0Ikfhhu"
      },
      "source": [
        "plt.plot(tmp[60,:])\r\n",
        "plt.plot(fake_paf[60,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyNOXzSkzqo5"
      },
      "source": [
        "X_train_nonLinear_features_2 = loaded_model.predict(X_train2)\n",
        "X_test_nonLinear_features_2 = loaded_model.predict(X_test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TabEPEQrVpFd"
      },
      "source": [
        "## 스케일링 수행하지 않고 비정상/정상 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96QnO9Mz0Y2a"
      },
      "source": [
        "pre2=clf.predict(X_test_df22[0:4389])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1P86JP71c_b"
      },
      "source": [
        "print(pre2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmUH7txM0hCk"
      },
      "source": [
        "for i in range(len(pre2)):\n",
        "  if pre2[i]==-1:\n",
        "    pre2[i]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18RY9ei_1DlU"
      },
      "source": [
        "print(pre2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yDyNlNr0jpI"
      },
      "source": [
        "y_pred_classes_paf_ori = np.zeros(shape=(4389,)) #비정상이니까 정답은 모두 0으로 채우자"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPv2PZCy0mk2"
      },
      "source": [
        "sns.heatmap(confusion_matrix(y_pred_classes_paf_ori,pre2), annot=True, fmt = '1.0f') #비정상 재생성 heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT72872K12N6"
      },
      "source": [
        "pre2_auto=clf2.predict(X_test_df22[0:4389])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZr-nDuP2B0U"
      },
      "source": [
        "for i in range(len(pre2_auto)):\n",
        "  if pre2_auto[i]==-1:\n",
        "    pre2_auto[i]=0\n",
        "y_pred_classes_paf_ori_auto = np.zeros(shape=(4389,)) #비정상이니까 정답은 모두 0으로 채우자\n",
        "ac2_auto=accuracy_score(pre2_auto,y_pred_classes_paf_ori_auto)\n",
        "print(ac2_auto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BASlCjJ82WDI"
      },
      "source": [
        "sns.heatmap(confusion_matrix(y_pred_classes_paf_ori_auto,pre2_auto), annot=True, fmt = '1.0f') #비정상 재생성 heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1hFkMnBFU6D"
      },
      "source": [
        "pre2_auto_2=clf3.predict(X_test_df22[0:4389]) #isolation forest 0.35520619731146047 병합 x 데이터에 대하여 /// "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_F7fgVTFZET"
      },
      "source": [
        "for i in range(len(pre2_auto_2)):\n",
        "  if pre2_auto_2[i]==-1:\n",
        "    pre2_auto_2[i]=0\n",
        "y_pred_classes_paf_ori_auto_2 = np.zeros(shape=(4389,)) #비정상이니까 정답은 모두 0으로 채우자\n",
        "ac2_auto=accuracy_score(pre2_auto_2,y_pred_classes_paf_ori_auto_2)\n",
        "print(ac2_auto)\n",
        "#0.6983367509683299 #0.6889174843171948"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNVhrC74FgtE"
      },
      "source": [
        "sns.heatmap(confusion_matrix(y_pred_classes_paf_ori_auto_2,pre2_auto_2), annot=True, fmt = '1.0f') #비정상 재생성 heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewDItHciV5EJ"
      },
      "source": [
        "## 스케일링 후 각 분류기별로 비정상 데이터를 정상/비정상 판별"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLgPQgcXNEA9"
      },
      "source": [
        "X_test_df22_plus = scaler.transform(X_test_df22)\r\n",
        "X_test_df22_plus = pca2.transform(X_test_df22_plus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr1YskZjgUNW"
      },
      "source": [
        "pre2_auto_22=if_clf.predict(X_test_df22_plus[0:4389]) #isolation forest 0.35520619731146047 병합 x 데이터에 대하여 /// "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T24nNnFNgWFc"
      },
      "source": [
        "for i in range(len(pre2_auto_22)):\n",
        "  if pre2_auto_22[i]==-1:\n",
        "    pre2_auto_22[i]=0\n",
        "y_pred_classes_paf_ori_auto_22 = np.zeros(shape=(4389,)) #비정상이니까 정답은 모두 0으로 채우자\n",
        "ac2_auto2=accuracy_score(pre2_auto_22,y_pred_classes_paf_ori_auto_22)\n",
        "print(ac2_auto2)\n",
        "#0.6983367509683299"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTlScckAWZvA"
      },
      "source": [
        "X_test_df22_min = minMaxScaler.transform(X_test_df22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJFitWYeWjG_"
      },
      "source": [
        "pre2_auto_min=clf4.predict(X_test_df22_min[0:9268]) #isolation forest 0.35520619731146047 병합 x 데이터에 대하여 /// "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "modT2gMjWmvz"
      },
      "source": [
        "for i in range(len(pre2_auto_min)):\r\n",
        "  if pre2_auto_min[i]==-1:\r\n",
        "    pre2_auto_min[i]=0\r\n",
        "y_pred_classes_paf_ori_auto_2_min = np.zeros(shape=(9268,)) #비정상이니까 정답은 모두 0으로 채우자\r\n",
        "ac2_auto_min=accuracy_score(pre2_auto_min,y_pred_classes_paf_ori_auto_2_min)\r\n",
        "print(ac2_auto_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUgrbJ7oSLdr"
      },
      "source": [
        "X_test_df22_max = maxAbsScaler.transform(X_test_df22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU8kkJ3BSGVs"
      },
      "source": [
        "pre2_auto_max=clf5.predict(X_test_df22_max[0:9268]) #isolation forest 0.35520619731146047 병합 x 데이터에 대하여 /// "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q421Z0OSebI"
      },
      "source": [
        "for i in range(len(pre2_auto_max)):\r\n",
        "  if pre2_auto_max[i]==-1:\r\n",
        "    pre2_auto_max[i]=0\r\n",
        "y_pred_classes_paf_ori_auto_2_max = np.zeros(shape=(9268,)) #비정상이니까 정답은 모두 0으로 채우자\r\n",
        "ac2_auto_max=accuracy_score(pre2_auto_max,y_pred_classes_paf_ori_auto_2_max)\r\n",
        "print(ac2_auto_max)\r\n",
        "#0.6983367509683299 #0.6889174843171948"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2bwHY7kpOt-"
      },
      "source": [
        "X_test_nonLinear_features_2_2 = ss.transform(X_test_df22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkgjHmM9TGJd"
      },
      "source": [
        "pre2_auto_scale=oc_svm_clf.predict(X_test_nonLinear_features_2_2[0:9268])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CowcQ-9cTSME"
      },
      "source": [
        "for i in range(len(pre2_auto_scale)):\r\n",
        "  if pre2_auto_scale[i]==-1:\r\n",
        "    pre2_auto_scale[i]=0\r\n",
        "y_pred_classes_paf_ori_auto_2_scale = np.zeros(shape=(9268,)) #비정상이니까 정답은 모두 0으로 채우자\r\n",
        "ac2_auto_max=accuracy_score(pre2_auto_scale,y_pred_classes_paf_ori_auto_2_scale)\r\n",
        "print(ac2_auto_max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClF1pw894ivw"
      },
      "source": [
        "X_test_nonLinear_features_2_2 = ss.transform(X_test_nonLinear_features_2)\r\n",
        "pre2_auto_scale=oc_svm_clf.predict(X_test_nonLinear_features_2_2[0:9268])\r\n",
        "for i in range(len(pre2_auto_scale)):\r\n",
        "  if pre2_auto_scale[i]==-1:\r\n",
        "    pre2_auto_scale[i]=0\r\n",
        "y_pred_classes_paf_ori_auto_2_scale = np.zeros(shape=(9268,)) #비정상이니까 정답은 모두 0으로 채우자\r\n",
        "ac2_auto_max=accuracy_score(pre2_auto_scale,y_pred_classes_paf_ori_auto_2_scale)\r\n",
        "print(ac2_auto_max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQJYUKOU14f8"
      },
      "source": [
        "## ---------------결과 합치기---------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af0r5XnFl6fT"
      },
      "source": [
        "a=confusion_matrix(y_pred_classes_paf_ori_auto_2,pre2_auto_2) # 비정상\n",
        "b=confusion_matrix(y_pred_classes_ori_df2_samll_10_2,pre_10_2) # 정상\n",
        "array_for_hmap = [[0 for col in range(2)] for row in range(2)] #2x2의 2차원 배열 생성\n",
        "array_for_hmap[0]=a[0] # 비정상을 첫줄에 할당\n",
        "# array_for_hmap[0][1]=0  # 이건 잘못된 경우에 전부 0으로 잡아 버려서 넣어준 값\n",
        "array_for_hmap[1]=b[1] # 정상을 두번째 줄에 할당"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "kqRkzy6ll-mS",
        "outputId": "00ded367-faa6-4766-ca2d-f01ede4a22e9"
      },
      "source": [
        "sns.heatmap(array_for_hmap, annot=True, fmt = '1.0f') #최종 heatmap 그리기"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8ed1e41550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}